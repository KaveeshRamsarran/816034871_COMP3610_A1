# COMP 3610: Big Data Analytics - Assignment 1
## NYC Yellow Taxi Trip Data Pipeline & Visualization Dashboard

**Student ID:** 816034871  
**Course:** COMP 3610 - Big Data Analytics  
**Due Date:** February 20, 2026

---

## üìã Project Overview

This project implements an end-to-end data pipeline that ingests, transforms, and analyzes the **NYC Yellow Taxi Trip dataset** (~3 million records from January 2024), culminating in an **interactive visualization dashboard** deployed on Streamlit Community Cloud.

### üîó Live Dashboard
**üöÄ Deployed URL:** [https://816034871-comp3610-a1.streamlit.app](https://816034871-comp3610-a1.streamlit.app)

> ‚ö†Ô∏è **Note:** Replace the above URL with your actual Streamlit Community Cloud deployment URL after deployment.

---

## üìÅ Repository Structure

```
816034871_COMP3610_A1/
‚îú‚îÄ‚îÄ assignment1.ipynb    # Jupyter notebook (Parts 1, 2, 3 prototypes)
‚îú‚îÄ‚îÄ app.py               # Streamlit main page (landing page)
‚îú‚îÄ‚îÄ pages/               # Streamlit multi-page navigation
‚îÇ   ‚îú‚îÄ‚îÄ 1_Overview.py    # Dataset statistics and quality checks
‚îÇ   ‚îî‚îÄ‚îÄ 2_Visualizations.py  # Interactive charts with filters
‚îú‚îÄ‚îÄ utils.py             # Data loading and processing utilities
‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies with version numbers
‚îú‚îÄ‚îÄ README.md            # Project documentation (this file)
‚îî‚îÄ‚îÄ .gitignore           # Git ignore rules (excludes data/)
```

**Note:** Data is downloaded directly from CloudFront URLs at runtime. No local data files are stored in the repository.

---

## üóÉÔ∏è Dataset

### Primary Dataset
- **NYC Yellow Taxi Trip Data (January 2024)**
- Source: [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
- URL: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet
- Records: ~3 million trips
- Format: Parquet

### Reference Dataset
- **Taxi Zone Lookup Table**
- URL: https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv
- Contains zone names and boroughs for location IDs

---

## üõ†Ô∏è Technologies Used

| Category | Technology | Version |
|----------|------------|----------|
| **Data Processing** | Python | 3.9+ |
| **Data Processing** | Pandas | >=2.0.0 |
| **Data Processing** | PyArrow | >=14.0.0 |
| **Database/SQL** | DuckDB | >=0.9.0 |
| **Visualization** | Plotly | >=5.18.0 |
| **Dashboard** | Streamlit | >=1.30.0 |
| **Deployment** | Streamlit Community Cloud | - |

---

## üöÄ Getting Started

### Prerequisites
- Python 3.9 or higher
- pip package manager

### Local Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/816034871_COMP3610_A1.git
   cd 816034871_COMP3610_A1
   ```

2. **Create a virtual environment (recommended)**
   ```bash
   python -m venv venv
   
   # Windows
   venv\Scripts\activate
   
   # macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Run the Jupyter Notebook**
   ```bash
   jupyter notebook assignment1.ipynb
   ```

5. **Run the Streamlit Dashboard**
   ```bash
   streamlit run app.py
   ```
   The dashboard will open at `http://localhost:8501`

---

## üìä Assignment Components

### Part 1: Data Ingestion & Storage (20 marks)

- ‚úÖ **Programmatic Download** (5 marks)
  - Downloads Parquet and CSV files using Python `requests` library
  - Progress tracking and error handling

- ‚úÖ **Data Validation** (10 marks)
  - Verifies expected columns exist
  - Validates datetime types
  - Reports row counts
  - Raises exceptions on validation failure

- ‚úÖ **File Organization** (5 marks)
  - Data saved to `data/raw/` directory
  - `.gitignore` excludes data directory

### Part 2: Data Transformation & Analysis (30 marks)

- ‚úÖ **Data Cleaning** (10 marks)
  - Removes null values in critical columns
  - Filters invalid trips (zero/negative distance, fare, duration)
  - Documents all removals with statistics

- ‚úÖ **Feature Engineering** (10 marks)
  - `trip_duration_minutes`: Trip duration in minutes
  - `trip_speed_mph`: Average speed in MPH
  - `pickup_hour`: Hour of pickup (0-23)
  - `pickup_day_of_week`: Day of week (0=Monday)

- ‚úÖ **SQL Analysis with DuckDB** (10 marks)
  1. Top 10 busiest pickup zones
  2. Average fare by hour of day
  3. Payment type distribution (percentages)
  4. Average tip percentage by day (credit card only)
  5. Top 5 pickup-dropoff zone pairs

### Part 3: Visualization Dashboard (40 marks)

- ‚úÖ **Dashboard Structure** (5 marks)
  - Clear title and introduction
  - Tab-based navigation (Overview, Locations, Payments, Temporal)

- ‚úÖ **Key Metrics** (5 marks)
  - Total trips
  - Average fare
  - Total revenue
  - Average distance
  - Average duration

- ‚úÖ **5 Visualizations** (20 marks)
  1. Bar chart: Top 10 pickup zones by borough
  2. Line chart: Average fare by hour
  3. Histogram: Trip distance distribution
  4. Pie chart: Payment type distribution
  5. Heatmap: Trips by day and hour

- ‚úÖ **Interactive Filters** (5 marks)
  - Date range selector
  - Hour range slider
  - Payment type multi-select dropdown

- ‚úÖ **Insights** (5 marks)
  - Each visualization includes 2-3 sentences of interpretation

### Part 4: Documentation & Code Quality (10 marks)

- ‚úÖ Notebook documentation with markdown cells
- ‚úÖ Clean, well-commented code
- ‚úÖ Proper repository organization

---

## üåê Deployment to Streamlit Cloud

### Step-by-Step Deployment Guide

1. **Push your code to GitHub**
   ```bash
   git add .
   git commit -m "Initial commit - Assignment 1"
   git push origin main
   ```

2. **Go to Streamlit Community Cloud**
   - Visit [share.streamlit.io](https://share.streamlit.io)
   - Sign in with your GitHub account

3. **Deploy your app**
   - Click "New app"
   - Select your repository: `816034871_COMP3610_A1`
   - Set main file path: `app.py`
   - Click "Deploy!"

4. **Wait for deployment**
   - Streamlit will install dependencies and launch your app
   - This may take 2-5 minutes on first deployment

5. **Get your public URL**
   - Your app will be available at: `https://your-app-name.streamlit.app`
   - Update this README with your actual URL

---

## üìà Key Findings

### Trip Patterns
- **Peak Hours:** Evening rush hour (5-7 PM) shows highest demand
- **Busiest Day:** Weekdays see more consistent traffic than weekends
- **Late Night:** Friday and Saturday nights have elevated late-night activity

### Location Insights
- **Manhattan Dominance:** Top pickup zones are concentrated in Manhattan
- **Common Routes:** Most trips are short-distance within Manhattan
- **Transit Hubs:** Penn Station, Grand Central areas are major pickup points

### Payment Analysis
- **Credit Card Preferred:** Vast majority of payments are by credit card
- **Consistent Tipping:** Average tip percentages hover around 18-20%
- **Cash Declining:** Cash payments represent a small minority

---

## üìö References

- [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [DuckDB Documentation](https://duckdb.org/docs/)
- [Plotly Python Documentation](https://plotly.com/python/)

---

*This project was completed as part of COMP 3610: Big Data Analytics at The University of the West Indies.*
